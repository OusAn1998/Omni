{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3fae0d-513b-4df0-ac34-cb699ae41a11",
   "metadata": {},
   "source": [
    "# Yolov8n model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f7013a9-14af-4750-abc0-f3f7d316754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8n.pt\") # pretrained COCO model laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49fbafe9-49b6-4e6f-b50f-a8a111261e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetectionModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (4): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (6): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Conv(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (8): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): SPPF(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (11): Concat()\n",
       "    (12): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (14): Concat()\n",
       "    (15): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (17): Concat()\n",
       "    (18): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (19): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (20): Concat()\n",
       "    (21): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (22): Detect(\n",
       "      (cv2): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (cv3): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (dfl): DFL(\n",
       "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model # Conv = Convolutional kernel, bn = batch normalization, act = activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeabd16-ac92-47a8-a9eb-ee806b81c691",
   "metadata": {},
   "source": [
    "# Image Controle\n",
    "Voordat we de images gaat splitsen in een training en validatie set moeten we controleren of de images geopend kunnen worden vanuit Python. Dit voorkomt dat we in de volgende stappen tegen fouten aanlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83887dbb-a3d5-4301-87a7-667719b095ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle afbeeldingen kunnen zonder problemen ingeladen worden\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "raw_images_folder = os.getcwd()+'/raw images/'\n",
    "for element in os.listdir(raw_images_folder):\n",
    "    image = cv2.imread(raw_images_folder+element)\n",
    "    if image is None:\n",
    "        print(f\"Fout: Kan afbeelding {element} niet laden. Controleer het bestandspad.\")\n",
    "print(\"Alle afbeeldingen kunnen zonder problemen ingeladen worden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5737c2-401d-4d99-a659-2b4fde726bae",
   "metadata": {},
   "source": [
    "# Splits Dataset in Training set and Validation set\n",
    "\n",
    "Nu gaan we de augmented images opsplitsen in training data en validation data. 80% van de augmented data gaan we gebruiken voor het finetunen van het YOLOv8n model en 20% gebruiken we voor de validatie. In de volgende stap gaan we de training set augmenteren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85510d90-ebb9-40a0-9a32-f0158b3228e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De dataset bestaat uit 450 images\n",
      "De training set bestaat uit 360.0 images\n",
      "De validatie set bestaat uit 90.0 images\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Ophalen van alla images\n",
    "raw_images_path = os.getcwd() + '/raw images'\n",
    "raw_images = os.listdir(raw_images_path) \n",
    "random.shuffle(raw_images)\n",
    "\n",
    "# Instellen van Paden\n",
    "train_images_path = os.getcwd() + \"/images/train\"\n",
    "val_images_path = os.getcwd() + \"/images/val\"\n",
    "\n",
    "# Splitsen van dataset in train en validation dataset\n",
    "train_images, val_images = train_test_split(raw_images, test_size=0.2)\n",
    "\n",
    "# Nu gaan we de images naar de juiste plaats verplaatsen\n",
    "for img in train_images:\n",
    "    shutil.copy(os.path.join(raw_images_path, img), train_images_path)\n",
    "for img in val_images:\n",
    "    shutil.copy(os.path.join(raw_images_path, img), val_images_path)\n",
    "\n",
    "print(f\"De dataset bestaat uit {len(raw_images)} images\")\n",
    "print(f\"De training set bestaat uit {0.8*len(raw_images)} images\")\n",
    "print(f\"De validatie set bestaat uit {0.2*len(raw_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52e51f-5ccb-40d9-b4ba-d508c626d483",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "In deze stap ga ik data augmentatie toepassen op de training set. Dit is een veelgebruikte techniek om je dataset te vergroten. Het voert allerlei image transformaties toe op je input images en slaat ze vervolgens op. Dit is een goede en snelle manier om je training set te verrijken en verhelpt deels het probleem van een te kleine training set. Zorg er wel voor dat de transformaties realistisch zijn. Na inspectie merkte ik op dat er van sommige klassen minder dan 15 images zaten in de validatie set. Vandaar dat ik een paar images verplaatst heb vanuit de training set naar de validatie set zodat elke klasse minstens 15 validatie images heeft. Vergeet niet om de verplaatste images volledig te verwijderen uit de training set om kruisbestuiving tussen de training en validatie set te voorkomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fdaf5bf6-a0d2-4dc7-a9d5-41db8a68f142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De training set bestaat uit 353 images\n",
      "De validatie set bestaat uit 97 images\n",
      "Afbeelding bank10.jpeg succesvol geladen\n",
      "Afbeelding bank11.jpeg succesvol geladen\n",
      "Afbeelding bank12.jpeg succesvol geladen\n",
      "Afbeelding bank13.jpeg succesvol geladen\n",
      "Afbeelding bank14.jpeg succesvol geladen\n",
      "Afbeelding bank15.jpeg succesvol geladen\n",
      "Afbeelding bank16.jpeg succesvol geladen\n",
      "Afbeelding bank20.jpeg succesvol geladen\n",
      "Afbeelding bank21.jpeg succesvol geladen\n",
      "Afbeelding bank22.jpeg succesvol geladen\n",
      "Afbeelding bank23.jpeg succesvol geladen\n",
      "Afbeelding bank24.jpeg succesvol geladen\n",
      "Afbeelding bank25.jpeg succesvol geladen\n",
      "Afbeelding bank26.jpeg succesvol geladen\n",
      "Afbeelding bank27.jpeg succesvol geladen\n",
      "Afbeelding bank28.jpeg succesvol geladen\n",
      "Afbeelding bank29.jpeg succesvol geladen\n",
      "Afbeelding bank30.jpeg succesvol geladen\n",
      "Afbeelding bank31.jpeg succesvol geladen\n",
      "Afbeelding bank32.jpeg succesvol geladen\n",
      "Afbeelding bank33.jpeg succesvol geladen\n",
      "Afbeelding bank34.jpeg succesvol geladen\n",
      "Afbeelding bank38.jpeg succesvol geladen\n",
      "Afbeelding bank40.jpeg succesvol geladen\n",
      "Afbeelding bank41.jpeg succesvol geladen\n",
      "Afbeelding bank42.jpeg succesvol geladen\n",
      "Afbeelding bank43.jpeg succesvol geladen\n",
      "Afbeelding bank44.jpeg succesvol geladen\n",
      "Afbeelding bank45.jpeg succesvol geladen\n",
      "Afbeelding bank46.jpeg succesvol geladen\n",
      "Afbeelding bank47.jpeg succesvol geladen\n",
      "Afbeelding bank48.jpeg succesvol geladen\n",
      "Afbeelding bank49.jpeg succesvol geladen\n",
      "Afbeelding bank50.jpeg succesvol geladen\n",
      "Afbeelding bank51.jpeg succesvol geladen\n",
      "Afbeelding bank52.jpeg succesvol geladen\n",
      "Afbeelding bank53.jpeg succesvol geladen\n",
      "Afbeelding bank54.jpeg succesvol geladen\n",
      "Afbeelding bank55.jpeg succesvol geladen\n",
      "Afbeelding bank56.jpeg succesvol geladen\n",
      "Afbeelding bank57.jpeg succesvol geladen\n",
      "Afbeelding bank58.jpeg succesvol geladen\n",
      "Afbeelding bank59.jpeg succesvol geladen\n",
      "Afbeelding bank6.jpeg succesvol geladen\n",
      "Afbeelding bank61.jpeg succesvol geladen\n",
      "Afbeelding bank62.jpeg succesvol geladen\n",
      "Afbeelding bank63.jpeg succesvol geladen\n",
      "Afbeelding bank64.jpeg succesvol geladen\n",
      "Afbeelding bank65.jpeg succesvol geladen\n",
      "Afbeelding bank66.jpeg succesvol geladen\n",
      "Afbeelding bank67.jpeg succesvol geladen\n",
      "Afbeelding bank68.jpeg succesvol geladen\n",
      "Afbeelding bank69.jpeg succesvol geladen\n",
      "Afbeelding bank7.jpeg succesvol geladen\n",
      "Afbeelding bank70.jpeg succesvol geladen\n",
      "Afbeelding bank71.jpeg succesvol geladen\n",
      "Afbeelding bank72.jpeg succesvol geladen\n",
      "Afbeelding bank75.jpeg succesvol geladen\n",
      "Afbeelding bank8.jpeg succesvol geladen\n",
      "Afbeelding bank9.jpeg succesvol geladen\n",
      "Afbeelding geert10.jpeg succesvol geladen\n",
      "Afbeelding geert11.jpeg succesvol geladen\n",
      "Afbeelding geert14.jpeg succesvol geladen\n",
      "Afbeelding geert15.jpeg succesvol geladen\n",
      "Afbeelding geert16.jpeg succesvol geladen\n",
      "Afbeelding geert17.jpeg succesvol geladen\n",
      "Afbeelding geert18.jpeg succesvol geladen\n",
      "Afbeelding geert19.jpeg succesvol geladen\n",
      "Afbeelding geert2.jpeg succesvol geladen\n",
      "Afbeelding geert20.jpeg succesvol geladen\n",
      "Afbeelding geert21.jpeg succesvol geladen\n",
      "Afbeelding geert22.jpeg succesvol geladen\n",
      "Afbeelding geert24.jpeg succesvol geladen\n",
      "Afbeelding geert25.jpeg succesvol geladen\n",
      "Afbeelding geert26.jpeg succesvol geladen\n",
      "Afbeelding geert27.jpeg succesvol geladen\n",
      "Afbeelding geert28.jpeg succesvol geladen\n",
      "Afbeelding geert3.jpeg succesvol geladen\n",
      "Afbeelding geert31.jpeg succesvol geladen\n",
      "Afbeelding geert32.jpeg succesvol geladen\n",
      "Afbeelding geert33.jpeg succesvol geladen\n",
      "Afbeelding geert35.jpeg succesvol geladen\n",
      "Afbeelding geert36.jpeg succesvol geladen\n",
      "Afbeelding geert37.jpeg succesvol geladen\n",
      "Afbeelding geert38.jpeg succesvol geladen\n",
      "Afbeelding geert39.jpeg succesvol geladen\n",
      "Afbeelding geert4.jpeg succesvol geladen\n",
      "Afbeelding geert41.jpeg succesvol geladen\n",
      "Afbeelding geert42.jpeg succesvol geladen\n",
      "Afbeelding geert43.jpeg succesvol geladen\n",
      "Afbeelding geert44.jpeg succesvol geladen\n",
      "Afbeelding geert45.jpeg succesvol geladen\n",
      "Afbeelding geert46.jpeg succesvol geladen\n",
      "Afbeelding geert48.jpeg succesvol geladen\n",
      "Afbeelding geert49.jpeg succesvol geladen\n",
      "Afbeelding geert5.jpeg succesvol geladen\n",
      "Afbeelding geert50.jpeg succesvol geladen\n",
      "Afbeelding geert51.jpeg succesvol geladen\n",
      "Afbeelding geert52.jpeg succesvol geladen\n",
      "Afbeelding geert53.jpeg succesvol geladen\n",
      "Afbeelding geert54.jpeg succesvol geladen\n",
      "Afbeelding geert55.jpeg succesvol geladen\n",
      "Afbeelding geert57.jpeg succesvol geladen\n",
      "Afbeelding geert58.jpeg succesvol geladen\n",
      "Afbeelding geert59.jpeg succesvol geladen\n",
      "Afbeelding geert6.jpeg succesvol geladen\n",
      "Afbeelding geert60.jpeg succesvol geladen\n",
      "Afbeelding geert62.jpeg succesvol geladen\n",
      "Afbeelding geert63.jpeg succesvol geladen\n",
      "Afbeelding geert66.jpeg succesvol geladen\n",
      "Afbeelding geert67.jpeg succesvol geladen\n",
      "Afbeelding geert68.jpeg succesvol geladen\n",
      "Afbeelding geert69.jpeg succesvol geladen\n",
      "Afbeelding geert7.jpeg succesvol geladen\n",
      "Afbeelding geert70.jpeg succesvol geladen\n",
      "Afbeelding geert71.jpeg succesvol geladen\n",
      "Afbeelding geert72.jpeg succesvol geladen\n",
      "Afbeelding geert73.jpeg succesvol geladen\n",
      "Afbeelding geert75.jpeg succesvol geladen\n",
      "Afbeelding geert9.jpeg succesvol geladen\n",
      "Afbeelding kat1.jpeg succesvol geladen\n",
      "Afbeelding kat11.jpeg succesvol geladen\n",
      "Afbeelding kat12.jpeg succesvol geladen\n",
      "Afbeelding kat13.jpeg succesvol geladen\n",
      "Afbeelding kat14.jpeg succesvol geladen\n",
      "Afbeelding kat17.jpeg succesvol geladen\n",
      "Afbeelding kat19.jpeg succesvol geladen\n",
      "Afbeelding kat20.jpeg succesvol geladen\n",
      "Afbeelding kat21.jpeg succesvol geladen\n",
      "Afbeelding kat22.jpeg succesvol geladen\n",
      "Afbeelding kat23.jpeg succesvol geladen\n",
      "Afbeelding kat26.jpeg succesvol geladen\n",
      "Afbeelding kat28.jpeg succesvol geladen\n",
      "Afbeelding kat29.jpeg succesvol geladen\n",
      "Afbeelding kat3.jpeg succesvol geladen\n",
      "Afbeelding kat30.jpeg succesvol geladen\n",
      "Afbeelding kat31.jpeg succesvol geladen\n",
      "Afbeelding kat32.jpeg succesvol geladen\n",
      "Afbeelding kat33.jpeg succesvol geladen\n",
      "Afbeelding kat34.jpeg succesvol geladen\n",
      "Afbeelding kat35.jpeg succesvol geladen\n",
      "Afbeelding kat36.jpeg succesvol geladen\n",
      "Afbeelding kat37.jpeg succesvol geladen\n",
      "Afbeelding kat38.jpeg succesvol geladen\n",
      "Afbeelding kat39.jpeg succesvol geladen\n",
      "Afbeelding kat4.jpeg succesvol geladen\n",
      "Afbeelding kat40.jpeg succesvol geladen\n",
      "Afbeelding kat42.jpeg succesvol geladen\n",
      "Afbeelding kat43.jpeg succesvol geladen\n",
      "Afbeelding kat44.jpeg succesvol geladen\n",
      "Afbeelding kat45.jpeg succesvol geladen\n",
      "Afbeelding kat46.jpeg succesvol geladen\n",
      "Afbeelding kat47.jpeg succesvol geladen\n",
      "Afbeelding kat48.jpeg succesvol geladen\n",
      "Afbeelding kat49.jpeg succesvol geladen\n",
      "Afbeelding kat5.jpeg succesvol geladen\n",
      "Afbeelding kat50.jpeg succesvol geladen\n",
      "Afbeelding kat52.jpeg succesvol geladen\n",
      "Afbeelding kat53.jpeg succesvol geladen\n",
      "Afbeelding kat54.jpeg succesvol geladen\n",
      "Afbeelding kat55.jpeg succesvol geladen\n",
      "Afbeelding kat56.jpeg succesvol geladen\n",
      "Afbeelding kat57.jpeg succesvol geladen\n",
      "Afbeelding kat58.jpeg succesvol geladen\n",
      "Afbeelding kat6.jpeg succesvol geladen\n",
      "Afbeelding kat60.jpeg succesvol geladen\n",
      "Afbeelding kat61.jpeg succesvol geladen\n",
      "Afbeelding kat62.jpeg succesvol geladen\n",
      "Afbeelding kat63.jpeg succesvol geladen\n",
      "Afbeelding kat64.jpeg succesvol geladen\n",
      "Afbeelding kat65.jpeg succesvol geladen\n",
      "Afbeelding kat68.jpeg succesvol geladen\n",
      "Afbeelding kat69.jpeg succesvol geladen\n",
      "Afbeelding kat71.jpeg succesvol geladen\n",
      "Afbeelding kat72.jpeg succesvol geladen\n",
      "Afbeelding kat73.jpeg succesvol geladen\n",
      "Afbeelding kat74.jpeg succesvol geladen\n",
      "Afbeelding kat75.jpeg succesvol geladen\n",
      "Afbeelding kat8.jpeg succesvol geladen\n",
      "Afbeelding kat9.jpeg succesvol geladen\n",
      "Afbeelding oussama1.jpeg succesvol geladen\n",
      "Afbeelding oussama10.jpeg succesvol geladen\n",
      "Afbeelding oussama12.jpeg succesvol geladen\n",
      "Afbeelding oussama13.jpeg succesvol geladen\n",
      "Afbeelding oussama14.jpeg succesvol geladen\n",
      "Afbeelding oussama15.jpeg succesvol geladen\n",
      "Afbeelding oussama16.jpeg succesvol geladen\n",
      "Afbeelding oussama19.jpeg succesvol geladen\n",
      "Afbeelding oussama2.jpeg succesvol geladen\n",
      "Afbeelding oussama21.jpeg succesvol geladen\n",
      "Afbeelding oussama22.jpeg succesvol geladen\n",
      "Afbeelding oussama23.jpeg succesvol geladen\n",
      "Afbeelding oussama24.jpeg succesvol geladen\n",
      "Afbeelding oussama25.jpeg succesvol geladen\n",
      "Afbeelding oussama26.jpeg succesvol geladen\n",
      "Afbeelding oussama27.jpeg succesvol geladen\n",
      "Afbeelding oussama28.jpeg succesvol geladen\n",
      "Afbeelding oussama29.jpeg succesvol geladen\n",
      "Afbeelding oussama3.jpeg succesvol geladen\n",
      "Afbeelding oussama30.jpeg succesvol geladen\n",
      "Afbeelding oussama31.jpeg succesvol geladen\n",
      "Afbeelding oussama34.jpeg succesvol geladen\n",
      "Afbeelding oussama36.jpeg succesvol geladen\n",
      "Afbeelding oussama38.jpeg succesvol geladen\n",
      "Afbeelding oussama39.jpeg succesvol geladen\n",
      "Afbeelding oussama4.jpeg succesvol geladen\n",
      "Afbeelding oussama41.jpeg succesvol geladen\n",
      "Afbeelding oussama43.jpeg succesvol geladen\n",
      "Afbeelding oussama45.jpeg succesvol geladen\n",
      "Afbeelding oussama46.jpeg succesvol geladen\n",
      "Afbeelding oussama48.jpeg succesvol geladen\n",
      "Afbeelding oussama49.jpeg succesvol geladen\n",
      "Afbeelding oussama51.jpeg succesvol geladen\n",
      "Afbeelding oussama52.jpeg succesvol geladen\n",
      "Afbeelding oussama54.jpeg succesvol geladen\n",
      "Afbeelding oussama55.jpeg succesvol geladen\n",
      "Afbeelding oussama56.jpeg succesvol geladen\n",
      "Afbeelding oussama57.jpeg succesvol geladen\n",
      "Afbeelding oussama58.jpeg succesvol geladen\n",
      "Afbeelding oussama59.jpeg succesvol geladen\n",
      "Afbeelding oussama6.jpeg succesvol geladen\n",
      "Afbeelding oussama61.jpeg succesvol geladen\n",
      "Afbeelding oussama62.jpeg succesvol geladen\n",
      "Afbeelding oussama63.jpeg succesvol geladen\n",
      "Afbeelding oussama64.jpeg succesvol geladen\n",
      "Afbeelding oussama65.jpeg succesvol geladen\n",
      "Afbeelding oussama66.jpeg succesvol geladen\n",
      "Afbeelding oussama67.jpeg succesvol geladen\n",
      "Afbeelding oussama68.jpeg succesvol geladen\n",
      "Afbeelding oussama69.jpeg succesvol geladen\n",
      "Afbeelding oussama71.jpeg succesvol geladen\n",
      "Afbeelding oussama72.jpeg succesvol geladen\n",
      "Afbeelding oussama73.jpeg succesvol geladen\n",
      "Afbeelding oussama75.jpeg succesvol geladen\n",
      "Afbeelding oussama8.jpeg succesvol geladen\n",
      "Afbeelding rutte1.jpeg succesvol geladen\n",
      "Afbeelding rutte10.jpeg succesvol geladen\n",
      "Afbeelding rutte11.jpeg succesvol geladen\n",
      "Afbeelding rutte12.jpeg succesvol geladen\n",
      "Afbeelding rutte13.jpeg succesvol geladen\n",
      "Afbeelding rutte14.jpeg succesvol geladen\n",
      "Afbeelding rutte16.jpeg succesvol geladen\n",
      "Afbeelding rutte17.jpeg succesvol geladen\n",
      "Afbeelding rutte19.jpeg succesvol geladen\n",
      "Afbeelding rutte2.jpeg succesvol geladen\n",
      "Afbeelding rutte20.jpeg succesvol geladen\n",
      "Afbeelding rutte21.jpeg succesvol geladen\n",
      "Afbeelding rutte22.jpeg succesvol geladen\n",
      "Afbeelding rutte23.jpeg succesvol geladen\n",
      "Afbeelding rutte24.jpeg succesvol geladen\n",
      "Afbeelding rutte25.jpeg succesvol geladen\n",
      "Afbeelding rutte26.jpeg succesvol geladen\n",
      "Afbeelding rutte27.jpeg succesvol geladen\n",
      "Afbeelding rutte28.jpeg succesvol geladen\n",
      "Afbeelding rutte3.jpeg succesvol geladen\n",
      "Afbeelding rutte30.jpeg succesvol geladen\n",
      "Afbeelding rutte31.jpeg succesvol geladen\n",
      "Afbeelding rutte32.jpeg succesvol geladen\n",
      "Afbeelding rutte35.jpeg succesvol geladen\n",
      "Afbeelding rutte36.jpeg succesvol geladen\n",
      "Afbeelding rutte37.jpeg succesvol geladen\n",
      "Afbeelding rutte38.jpeg succesvol geladen\n",
      "Afbeelding rutte4.jpeg succesvol geladen\n",
      "Afbeelding rutte41.jpeg succesvol geladen\n",
      "Afbeelding rutte44.jpeg succesvol geladen\n",
      "Afbeelding rutte45.jpeg succesvol geladen\n",
      "Afbeelding rutte46.jpeg succesvol geladen\n",
      "Afbeelding rutte47.jpeg succesvol geladen\n",
      "Afbeelding rutte49.jpeg succesvol geladen\n",
      "Afbeelding rutte5.jpeg succesvol geladen\n",
      "Afbeelding rutte52.jpeg succesvol geladen\n",
      "Afbeelding rutte53.jpeg succesvol geladen\n",
      "Afbeelding rutte55.jpeg succesvol geladen\n",
      "Afbeelding rutte56.jpeg succesvol geladen\n",
      "Afbeelding rutte57.jpeg succesvol geladen\n",
      "Afbeelding rutte58.jpeg succesvol geladen\n",
      "Afbeelding rutte6.jpeg succesvol geladen\n",
      "Afbeelding rutte60.jpeg succesvol geladen\n",
      "Afbeelding rutte61.jpeg succesvol geladen\n",
      "Afbeelding rutte62.jpeg succesvol geladen\n",
      "Afbeelding rutte63.jpeg succesvol geladen\n",
      "Afbeelding rutte64.jpeg succesvol geladen\n",
      "Afbeelding rutte65.jpeg succesvol geladen\n",
      "Afbeelding rutte66.jpeg succesvol geladen\n",
      "Afbeelding rutte67.jpeg succesvol geladen\n",
      "Afbeelding rutte7.jpeg succesvol geladen\n",
      "Afbeelding rutte70.jpeg succesvol geladen\n",
      "Afbeelding rutte71.jpeg succesvol geladen\n",
      "Afbeelding rutte72.jpeg succesvol geladen\n",
      "Afbeelding rutte73.jpeg succesvol geladen\n",
      "Afbeelding rutte74.jpeg succesvol geladen\n",
      "Afbeelding rutte75.jpeg succesvol geladen\n",
      "Afbeelding rutte8.jpeg succesvol geladen\n",
      "Afbeelding trump10.jpeg succesvol geladen\n",
      "Afbeelding trump11.jpeg succesvol geladen\n",
      "Afbeelding trump12.jpeg succesvol geladen\n",
      "Afbeelding trump14.jpeg succesvol geladen\n",
      "Afbeelding trump16.jpeg succesvol geladen\n",
      "Afbeelding trump17.jpeg succesvol geladen\n",
      "Afbeelding trump18.jpeg succesvol geladen\n",
      "Afbeelding trump19.jpeg succesvol geladen\n",
      "Afbeelding trump22.jpeg succesvol geladen\n",
      "Afbeelding trump23.jpeg succesvol geladen\n",
      "Afbeelding trump24.jpeg succesvol geladen\n",
      "Afbeelding trump26.jpeg succesvol geladen\n",
      "Afbeelding trump27.jpeg succesvol geladen\n",
      "Afbeelding trump29.jpeg succesvol geladen\n",
      "Afbeelding trump3.jpeg succesvol geladen\n",
      "Afbeelding trump30.jpeg succesvol geladen\n",
      "Afbeelding trump31.jpeg succesvol geladen\n",
      "Afbeelding trump32.jpeg succesvol geladen\n",
      "Afbeelding trump33.jpeg succesvol geladen\n",
      "Afbeelding trump34.jpeg succesvol geladen\n",
      "Afbeelding trump35.jpeg succesvol geladen\n",
      "Afbeelding trump36.jpeg succesvol geladen\n",
      "Afbeelding trump38.jpeg succesvol geladen\n",
      "Afbeelding trump39.jpeg succesvol geladen\n",
      "Afbeelding trump4.jpeg succesvol geladen\n",
      "Afbeelding trump40.jpeg succesvol geladen\n",
      "Afbeelding trump41.jpeg succesvol geladen\n",
      "Afbeelding trump43.jpeg succesvol geladen\n",
      "Afbeelding trump44.jpeg succesvol geladen\n",
      "Afbeelding trump45.jpeg succesvol geladen\n",
      "Afbeelding trump46.jpeg succesvol geladen\n",
      "Afbeelding trump47.jpeg succesvol geladen\n",
      "Afbeelding trump49.jpeg succesvol geladen\n",
      "Afbeelding trump5.jpeg succesvol geladen\n",
      "Afbeelding trump50.jpeg succesvol geladen\n",
      "Afbeelding trump51.jpeg succesvol geladen\n",
      "Afbeelding trump52.jpeg succesvol geladen\n",
      "Afbeelding trump53.jpeg succesvol geladen\n",
      "Afbeelding trump54.jpeg succesvol geladen\n",
      "Afbeelding trump56.jpeg succesvol geladen\n",
      "Afbeelding trump57.jpeg succesvol geladen\n",
      "Afbeelding trump58.jpeg succesvol geladen\n",
      "Afbeelding trump59.jpeg succesvol geladen\n",
      "Afbeelding trump6.jpeg succesvol geladen\n",
      "Afbeelding trump60.jpeg succesvol geladen\n",
      "Afbeelding trump61.jpeg succesvol geladen\n",
      "Afbeelding trump62.jpeg succesvol geladen\n",
      "Afbeelding trump63.jpeg succesvol geladen\n",
      "Afbeelding trump64.jpeg succesvol geladen\n",
      "Afbeelding trump65.jpeg succesvol geladen\n",
      "Afbeelding trump66.jpeg succesvol geladen\n",
      "Afbeelding trump67.jpeg succesvol geladen\n",
      "Afbeelding trump68.jpeg succesvol geladen\n",
      "Afbeelding trump69.jpeg succesvol geladen\n",
      "Afbeelding trump70.jpeg succesvol geladen\n",
      "Afbeelding trump71.jpeg succesvol geladen\n",
      "Afbeelding trump72.jpeg succesvol geladen\n",
      "Afbeelding trump74.jpeg succesvol geladen\n",
      "Afbeelding trump75.jpeg succesvol geladen\n",
      "Afbeelding trump8.jpeg succesvol geladen\n"
     ]
    }
   ],
   "source": [
    "# Laten we eerst Data Augmentatie toepassen\n",
    "import albumentations as alb\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Aantal images in de training set en validatie set voor augmentatie \n",
    "train_images_folder = os.getcwd() + \"/images/train\"\n",
    "train_images = os.listdir(train_images_path)\n",
    "val_images_folder = os.getcwd() + \"/images/val\"\n",
    "val_images = os.listdir(val_images_path)\n",
    "print(f\"De training set bestaat uit {len(train_images)} images\")\n",
    "print(f\"De validatie set bestaat uit {len(val_images)} images\")\n",
    "\n",
    "# Bepaal nu alle transformaties die je wilt toepassen op de foto's \n",
    "transform = alb.Compose([\n",
    "    alb.RandomRotate90(p=0.5),\n",
    "    alb.HorizontalFlip(p=0.5),\n",
    "    alb.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    alb.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
    "    alb.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.3),\n",
    "    alb.Blur(blur_limit=3, p=0.2),\n",
    "    alb.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "    alb.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=0.2)\n",
    "])\n",
    "\n",
    "# Laten we de transformaties toepassen op onze images\n",
    "num_augmented_images = 2 # aantal augmentaties per afbeelding\n",
    "\n",
    "for image_name in train_images:\n",
    "    train_image_path = os.path.join(train_images_folder, image_name)\n",
    "    image = cv2.imread(train_image_path)\n",
    "\n",
    "    for i in range(num_augmented_images):\n",
    "        augmented = transform(image=image)\n",
    "        augmented_image = augmented[\"image\"]\n",
    "        output_path = os.path.join(train_images_folder, f\"aug_{i}_{image_name}\")\n",
    "        cv2.imwrite(output_path, augmented_image)\n",
    "\n",
    "train_images = os.listdir(train_images_path)\n",
    "val_images = os.listdir(val_images_path)\n",
    "print(f\"De training set bestaat uit {len(train_images)} images\")\n",
    "print(f\"De validatie set bestaat uit {len(val_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd39f39-d848-471c-8cea-630e3e1c905a",
   "metadata": {},
   "source": [
    "# Train het Model\n",
    "In deze module gaan we het pretrained YOLOv8n model trainen op onze custom dataset. Ik wil dat het model na het trainen in staat is om de 80 classes van de COCO dataset te herkennen. Daarnaast wil ik het finetunen met mijn dataset zodat hij ook mijn custom classes kan herkennen. Als test heb ik maar 1 custom class gebruikt in mijn custom dataset. Als het werkt dan zal ik er meerdere classes aan toevoegen. Dus voor nu herkent hij 81 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e65f83e-abb1-49e1-baf5-80219c61e165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale aantal lagen: 23\n",
      "Ultralytics 8.3.36  Python-3.9.20 torch-2.5.1+cpu CPU (12th Gen Intel Core(TM) i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=custom_dataset.yaml, epochs=50, time=None, patience=10, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=22, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=81\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    906541  ultralytics.nn.modules.head.Detect           [81, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3,166,077 parameters, 3,166,061 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.12.cv1.conv.weight'\n",
      "Freezing layer 'model.12.cv1.bn.weight'\n",
      "Freezing layer 'model.12.cv1.bn.bias'\n",
      "Freezing layer 'model.12.cv2.conv.weight'\n",
      "Freezing layer 'model.12.cv2.bn.weight'\n",
      "Freezing layer 'model.12.cv2.bn.bias'\n",
      "Freezing layer 'model.12.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.12.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.12.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.12.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.12.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.12.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.15.cv1.conv.weight'\n",
      "Freezing layer 'model.15.cv1.bn.weight'\n",
      "Freezing layer 'model.15.cv1.bn.bias'\n",
      "Freezing layer 'model.15.cv2.conv.weight'\n",
      "Freezing layer 'model.15.cv2.bn.weight'\n",
      "Freezing layer 'model.15.cv2.bn.bias'\n",
      "Freezing layer 'model.15.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.15.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.15.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.15.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.15.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.15.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.16.conv.weight'\n",
      "Freezing layer 'model.16.bn.weight'\n",
      "Freezing layer 'model.16.bn.bias'\n",
      "Freezing layer 'model.18.cv1.conv.weight'\n",
      "Freezing layer 'model.18.cv1.bn.weight'\n",
      "Freezing layer 'model.18.cv1.bn.bias'\n",
      "Freezing layer 'model.18.cv2.conv.weight'\n",
      "Freezing layer 'model.18.cv2.bn.weight'\n",
      "Freezing layer 'model.18.cv2.bn.bias'\n",
      "Freezing layer 'model.18.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.18.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.18.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.18.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.18.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.18.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.19.conv.weight'\n",
      "Freezing layer 'model.19.bn.weight'\n",
      "Freezing layer 'model.19.bn.bias'\n",
      "Freezing layer 'model.21.cv1.conv.weight'\n",
      "Freezing layer 'model.21.cv1.bn.weight'\n",
      "Freezing layer 'model.21.cv1.bn.bias'\n",
      "Freezing layer 'model.21.cv2.conv.weight'\n",
      "Freezing layer 'model.21.cv2.bn.weight'\n",
      "Freezing layer 'model.21.cv2.bn.bias'\n",
      "Freezing layer 'model.21.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.21.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.21.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.21.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.21.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.21.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\OussamaAkhiyat\\Documents\\Python Codes\\Omni\\labels\\train.cache... 120 images, 0 backgrounds, 0 corrupt: 100%|██████████| 120/120 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\OussamaAkhiyat\\Documents\\Python Codes\\Omni\\labels\\val.cache... 30 images, 0 backgrounds, 0 corrupt: 100%|██████████| 30/30 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000118, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G     0.9333      4.927      1.349         18        640: 100%|██████████| 15/15 [00:48<00:00,  3.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:07<00:00,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G     0.8699      4.732      1.275         20        640: 100%|██████████| 15/15 [00:43<00:00,  2.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G     0.8703      4.582      1.267         22        640: 100%|██████████| 15/15 [00:40<00:00,  2.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G     0.9085      4.376       1.32         28        640: 100%|██████████| 15/15 [00:39<00:00,  2.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G     0.8912      4.121      1.313         19        640: 100%|██████████| 15/15 [00:42<00:00,  2.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G     0.9393      3.884      1.375         17        640: 100%|██████████| 15/15 [00:45<00:00,  3.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:07<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30          1      0.167      0.583      0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      0.949      3.622      1.365         15        640: 100%|██████████| 15/15 [00:40<00:00,  2.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.585        0.8      0.795      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G      1.026      3.317      1.431         21        640: 100%|██████████| 15/15 [00:41<00:00,  2.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.418      0.933       0.85        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G     0.9569      2.987      1.358         20        640: 100%|██████████| 15/15 [00:42<00:00,  2.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.894      0.564      0.862        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      1.011      2.825      1.426         22        640: 100%|██████████| 15/15 [00:42<00:00,  2.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.796       0.78      0.864      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G     0.9154        2.6      1.318         24        640: 100%|██████████| 15/15 [00:44<00:00,  2.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.752      0.808      0.874        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      0.981      2.395      1.402         25        640: 100%|██████████| 15/15 [00:40<00:00,  2.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.785      0.853      0.902      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G     0.9392      2.183      1.399         20        640: 100%|██████████| 15/15 [00:41<00:00,  2.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.765      0.869        0.9      0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G     0.9734      2.053      1.406         24        640: 100%|██████████| 15/15 [00:46<00:00,  3.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30       0.86      0.867      0.912      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G     0.9203      1.947      1.416         22        640: 100%|██████████| 15/15 [00:44<00:00,  2.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.928      0.856      0.923      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G     0.9215      1.927      1.407         23        640: 100%|██████████| 15/15 [00:41<00:00,  2.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:07<00:00,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.951      0.867      0.934      0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G     0.8933       1.87       1.38         19        640: 100%|██████████| 15/15 [00:43<00:00,  2.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.947      0.867      0.943      0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G     0.9309       1.74      1.426         22        640: 100%|██████████| 15/15 [00:42<00:00,  2.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.962      0.838       0.95      0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G     0.8748       1.72      1.385         17        640: 100%|██████████| 15/15 [00:39<00:00,  2.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30          1      0.829      0.957      0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G     0.8982      1.637      1.374         21        640: 100%|██████████| 15/15 [00:44<00:00,  2.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.995      0.833      0.963      0.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G     0.8593      1.579      1.347         17        640: 100%|██████████| 15/15 [00:41<00:00,  2.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30          1      0.867      0.979      0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G     0.8709      1.624      1.391         17        640: 100%|██████████| 15/15 [00:39<00:00,  2.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.932       0.92      0.982      0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G     0.8235      1.501      1.321         21        640: 100%|██████████| 15/15 [00:41<00:00,  2.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.965      0.932      0.987      0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G     0.9072      1.665      1.397         19        640: 100%|██████████| 15/15 [00:43<00:00,  2.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30       0.99      0.933      0.988      0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G     0.8954      1.702      1.345         18        640: 100%|██████████| 15/15 [00:41<00:00,  2.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.966      0.945      0.983      0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G     0.9437      1.696      1.419         21        640: 100%|██████████| 15/15 [00:38<00:00,  2.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.917      0.933      0.982      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G     0.8468      1.507      1.339         23        640: 100%|██████████| 15/15 [00:38<00:00,  2.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.945      0.933      0.982      0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G     0.8693       1.54      1.363         16        640: 100%|██████████| 15/15 [00:38<00:00,  2.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.966      0.954      0.984      0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50         0G     0.8526      1.602      1.342         21        640: 100%|██████████| 15/15 [00:38<00:00,  2.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.967      0.964      0.982      0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50         0G     0.8733      1.486      1.357         25        640: 100%|██████████| 15/15 [00:40<00:00,  2.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.967      0.966      0.982      0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50         0G     0.8885      1.553      1.376         21        640: 100%|██████████| 15/15 [00:41<00:00,  2.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.957          1      0.987      0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50         0G     0.8956      1.553      1.396         16        640: 100%|██████████| 15/15 [00:43<00:00,  2.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.966          1      0.992      0.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50         0G     0.8445      1.487      1.353         18        640: 100%|██████████| 15/15 [00:39<00:00,  2.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.964          1      0.995       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G     0.8756      1.634      1.395         20        640: 100%|██████████| 15/15 [00:37<00:00,  2.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.968          1      0.985      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50         0G     0.8236      1.448      1.322         21        640: 100%|██████████| 15/15 [00:38<00:00,  2.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.968      0.998       0.99      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50         0G     0.8752      1.555      1.369         26        640: 100%|██████████| 15/15 [00:39<00:00,  2.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.967      0.987      0.992      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50         0G     0.7923      1.483      1.339         18        640: 100%|██████████| 15/15 [00:39<00:00,  2.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.967      0.992      0.993      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50         0G     0.8563      1.533      1.328         19        640: 100%|██████████| 15/15 [00:41<00:00,  2.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.967      0.977      0.994      0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50         0G     0.8912      1.453       1.37         26        640: 100%|██████████| 15/15 [00:40<00:00,  2.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.976      0.967      0.994      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G     0.8406      1.549      1.337         20        640: 100%|██████████| 15/15 [00:39<00:00,  2.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.984      0.967      0.994      0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50         0G      1.024      2.653      1.607          8        640: 100%|██████████| 15/15 [00:38<00:00,  2.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30          1      0.994      0.995      0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50         0G     0.9931      2.568      1.559          8        640: 100%|██████████| 15/15 [00:39<00:00,  2.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.965      0.912      0.987      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50         0G     0.9726      2.656      1.503          8        640: 100%|██████████| 15/15 [00:44<00:00,  2.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.935      0.963      0.978      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50         0G     0.9802      2.485      1.502          8        640: 100%|██████████| 15/15 [00:38<00:00,  2.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.893      0.967      0.964      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50         0G     0.9715      2.577      1.502          8        640: 100%|██████████| 15/15 [00:40<00:00,  2.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.841      0.967      0.967      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50         0G     0.9784      2.395      1.514          8        640: 100%|██████████| 15/15 [00:43<00:00,  2.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.851      0.953      0.953      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50         0G     0.9217      2.511       1.47          8        640: 100%|██████████| 15/15 [00:42<00:00,  2.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.859      0.933      0.958      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         0G     0.9273      2.518      1.457          8        640: 100%|██████████| 15/15 [00:39<00:00,  2.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.824      0.967      0.972      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G     0.8962       2.49      1.452          8        640: 100%|██████████| 15/15 [00:40<00:00,  2.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.808      0.985      0.962      0.627\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 39, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "49 epochs completed in 0.664 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.5MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.36  Python-3.9.20 torch-2.5.1+cpu CPU (12th Gen Intel Core(TM) i5-1235U)\n",
      "Model summary (fused): 168 layers, 3,160,775 parameters, 0 gradients, 8.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         30      0.981      0.967      0.994      0.736\n",
      "               Oussama         30         30      0.981      0.967      0.994      0.736\n",
      "Speed: 2.7ms preprocess, 155.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([80])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000021DD3CBFB20>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "            0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,\n",
       "            0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,     0.96774,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.15385,     0.15385,     0.22731,     0.29488,     0.34935,     0.40397,     0.45023,     0.50053,     0.51848,     0.54091,     0.56379,     0.57815,     0.58717,     0.60669,     0.61026,     0.62572,      0.6539,     0.67213,     0.69106,     0.70184,     0.72422,     0.73167,     0.74203,\n",
       "            0.74414,     0.74624,     0.74834,     0.75173,     0.76211,     0.77457,     0.79018,     0.79291,     0.79562,     0.79833,     0.80137,     0.80497,     0.80855,     0.81384,     0.82196,     0.82487,     0.82776,     0.83065,     0.83396,     0.84381,     0.84824,     0.85185,     0.85544,\n",
       "            0.86274,     0.87568,     0.88327,     0.88476,     0.88626,     0.88774,     0.88923,     0.89071,     0.89219,     0.89366,     0.89513,     0.90929,      0.9101,     0.91092,     0.91173,     0.91254,     0.91334,     0.91415,     0.91496,     0.91576,     0.91656,     0.91737,     0.91817,\n",
       "            0.91897,     0.91977,     0.92056,     0.92136,     0.92215,     0.92295,     0.92378,     0.92461,     0.92545,     0.92628,     0.92711,     0.92794,     0.92877,      0.9296,     0.93043,     0.93125,     0.93208,      0.9329,     0.93372,     0.93454,     0.93536,     0.93618,     0.93699,\n",
       "            0.93791,     0.93897,     0.94004,      0.9411,     0.94216,     0.94322,     0.94428,     0.94533,     0.94639,     0.94744,     0.94848,     0.94953,     0.95058,     0.95162,     0.95265,     0.95367,     0.95468,     0.95569,      0.9567,      0.9577,     0.95871,     0.95971,     0.96071,\n",
       "            0.96171,     0.96271,      0.9637,     0.96469,     0.96568,     0.96667,     0.96766,      0.9687,     0.96973,     0.97077,      0.9718,     0.97283,     0.97386,     0.97489,     0.97591,     0.97694,     0.97796,     0.97898,     0.97999,     0.98101,     0.98202,     0.98303,     0.98335,\n",
       "            0.98274,     0.98213,     0.98152,     0.98091,      0.9803,     0.97969,     0.97907,     0.97846,     0.97785,     0.97723,     0.97662,       0.976,     0.97539,     0.97477,     0.97415,     0.97353,     0.97291,     0.97229,     0.97167,     0.97105,     0.97043,     0.96981,     0.96918,\n",
       "            0.96856,     0.96793,     0.96731,     0.96668,      0.9677,     0.96876,     0.96982,     0.97087,     0.97192,     0.97297,     0.97402,     0.97507,     0.97611,     0.97715,     0.97819,     0.97922,     0.98026,     0.98129,     0.98232,     0.98294,     0.98256,     0.98219,     0.98181,\n",
       "            0.98143,     0.98105,     0.98067,     0.98029,     0.97991,     0.97953,     0.97915,     0.97877,     0.97839,       0.978,     0.97762,     0.97724,     0.97686,     0.97647,     0.97609,     0.97571,     0.97532,     0.97494,     0.97456,     0.97417,     0.97379,      0.9734,     0.97302,\n",
       "            0.97263,     0.97224,     0.97186,     0.97147,     0.97108,      0.9707,     0.97031,     0.96992,     0.96953,     0.96915,     0.96876,     0.96837,     0.96798,     0.96759,      0.9672,     0.96681,     0.96642,     0.96603,     0.96564,     0.96452,     0.96308,     0.96163,     0.96018,\n",
       "            0.95873,     0.95727,     0.95581,     0.95434,     0.95287,      0.9514,     0.94992,     0.94844,     0.94731,     0.94709,     0.94688,     0.94666,     0.94644,     0.94623,     0.94601,     0.94579,     0.94558,     0.94536,     0.94514,     0.94493,     0.94471,     0.94449,     0.94428,\n",
       "            0.94406,     0.94384,     0.94363,     0.94341,     0.94319,     0.94297,     0.94276,     0.94254,     0.94232,      0.9421,     0.94188,     0.94167,     0.94145,     0.94123,     0.94101,     0.94079,     0.94057,     0.94035,     0.94014,     0.93992,      0.9397,     0.93948,     0.93926,\n",
       "            0.93904,     0.93882,      0.9386,     0.93838,     0.93816,     0.93794,     0.93772,      0.9375,     0.93728,     0.93706,     0.93684,     0.93662,      0.9364,     0.93618,     0.93596,     0.93574,     0.93552,      0.9353,     0.93508,     0.93486,     0.93464,     0.93442,     0.93419,\n",
       "            0.93397,     0.93375,     0.93353,     0.93331,     0.93309,     0.93286,     0.93264,     0.93242,      0.9322,     0.93198,     0.93175,     0.93153,     0.93131,     0.93109,     0.93086,     0.93064,     0.93042,      0.9302,     0.92997,     0.92975,     0.92953,      0.9293,     0.92908,\n",
       "            0.92886,     0.92863,     0.91175,     0.90609,     0.90268,     0.89925,      0.8958,     0.89233,     0.88881,     0.88361,     0.87836,     0.87306,     0.86731,     0.85193,     0.84539,     0.84419,     0.84298,     0.84176,     0.84055,     0.83933,     0.83811,     0.83689,     0.83567,\n",
       "            0.83444,     0.83321,     0.83198,     0.83074,      0.8295,     0.82826,     0.82702,     0.82577,     0.82453,      0.8222,     0.81564,     0.80901,      0.8023,     0.79983,     0.79957,     0.79931,     0.79905,     0.79879,     0.79853,     0.79827,     0.79801,     0.79775,     0.79748,\n",
       "            0.79722,     0.79696,      0.7967,     0.79644,     0.79618,     0.79592,     0.79565,     0.79539,     0.79513,     0.79487,     0.79461,     0.79434,     0.79408,     0.79382,     0.79356,     0.79329,     0.79303,     0.79277,      0.7925,     0.79224,     0.79198,     0.79172,     0.79145,\n",
       "            0.79119,     0.79092,     0.79066,      0.7904,     0.79013,     0.78987,      0.7896,     0.78934,     0.78907,     0.78881,     0.78854,     0.78828,     0.78801,     0.78775,     0.78748,     0.78722,     0.78695,     0.78669,     0.78642,     0.78616,     0.78589,     0.78562,     0.78536,\n",
       "            0.78509,     0.78483,     0.78456,     0.78429,     0.78403,     0.78376,     0.78349,     0.78322,     0.78296,     0.78269,     0.78242,     0.78215,     0.78189,     0.78162,     0.78135,     0.78108,     0.78081,     0.78055,     0.78028,     0.78001,     0.77974,     0.77947,      0.7792,\n",
       "            0.77893,     0.77866,      0.7784,     0.77813,     0.77786,     0.77759,     0.77732,     0.77705,     0.77678,     0.77651,     0.77624,     0.77597,      0.7757,     0.77538,     0.77498,     0.77458,     0.77417,     0.77377,     0.77337,     0.77296,     0.77256,     0.77215,     0.77175,\n",
       "            0.77134,     0.77094,     0.77053,     0.77012,     0.76972,     0.76931,      0.7689,      0.7685,     0.76809,     0.76768,     0.76727,     0.76686,     0.76645,     0.76605,     0.76564,     0.76523,     0.76482,     0.76441,       0.764,     0.76359,     0.76318,     0.76276,     0.76235,\n",
       "            0.76194,     0.76153,     0.76112,      0.7607,     0.76029,     0.75988,     0.75946,     0.75905,     0.75864,     0.75822,     0.75781,     0.75739,     0.75698,     0.75656,     0.75615,     0.75573,     0.75532,      0.7549,     0.75448,     0.75407,     0.75365,     0.75323,     0.75281,\n",
       "             0.7524,     0.75198,     0.75156,     0.75114,     0.75072,      0.7503,     0.74991,     0.74961,      0.7493,       0.749,     0.74869,     0.74839,     0.74808,     0.74778,     0.74747,     0.74717,     0.74686,     0.74655,     0.74625,     0.74594,     0.74563,     0.74533,     0.74502,\n",
       "            0.74471,     0.74441,      0.7441,     0.74379,     0.74348,     0.74318,     0.74287,     0.74256,     0.74225,     0.74194,     0.74163,     0.74132,     0.74102,     0.74071,      0.7404,     0.74009,     0.73978,     0.73947,     0.73916,     0.73885,     0.73854,     0.73823,     0.73792,\n",
       "            0.73761,      0.7373,     0.73699,     0.73667,     0.73636,     0.73605,     0.73574,     0.73543,     0.73512,     0.73481,     0.73449,     0.73418,     0.73387,     0.73356,     0.73324,     0.73293,     0.73262,      0.7323,     0.73199,     0.73168,     0.73136,     0.73105,     0.73074,\n",
       "            0.73042,     0.73011,     0.72979,     0.72948,     0.72916,     0.72885,     0.72853,     0.72822,      0.7279,     0.72759,     0.72727,     0.72695,     0.72664,     0.72632,     0.72601,     0.72569,     0.72537,     0.72506,     0.72474,     0.72442,     0.72411,     0.72379,     0.72347,\n",
       "            0.72258,     0.72154,      0.7205,     0.71945,      0.7184,     0.71736,     0.71631,     0.71525,      0.7142,     0.71315,     0.71209,     0.71103,     0.70997,     0.70891,     0.70784,     0.70678,     0.70571,     0.70464,     0.70357,      0.7025,     0.70142,     0.70035,     0.69927,\n",
       "            0.69819,     0.69711,     0.69603,     0.69513,     0.69432,     0.69352,     0.69271,     0.69191,      0.6911,     0.69029,     0.68948,     0.68867,     0.68786,     0.68705,     0.68624,     0.68542,     0.68461,     0.68379,     0.68297,     0.68216,     0.68134,     0.68052,      0.6797,\n",
       "            0.67887,     0.67805,     0.67723,      0.6764,     0.67557,     0.67475,     0.67392,     0.67309,     0.67226,     0.67143,     0.67059,     0.66976,     0.66893,     0.66809,     0.66725,     0.66651,     0.66597,     0.66543,     0.66489,     0.66435,     0.66381,     0.66327,     0.66273,\n",
       "            0.66219,     0.66165,      0.6611,     0.66056,     0.66002,     0.65947,     0.65893,     0.65839,     0.65784,      0.6573,     0.65675,      0.6562,     0.65566,     0.65511,     0.65456,     0.65401,     0.65347,     0.65292,     0.65237,     0.65182,     0.65127,     0.65072,     0.65017,\n",
       "            0.64961,     0.64906,     0.64851,     0.64796,      0.6474,     0.64685,     0.64629,     0.64574,     0.64518,     0.64463,     0.64407,     0.64352,     0.64296,      0.6424,     0.64184,     0.64129,     0.64073,     0.64017,     0.63961,     0.63905,     0.63849,     0.63793,     0.63736,\n",
       "             0.6368,     0.63629,     0.63594,     0.63559,     0.63524,     0.63489,     0.63454,     0.63419,     0.63384,     0.63349,     0.63314,     0.63279,     0.63244,     0.63209,     0.63174,     0.63139,     0.63104,     0.63069,     0.63034,     0.62998,     0.62963,     0.62928,     0.62893,\n",
       "            0.62858,     0.62822,     0.62787,     0.62752,     0.62716,     0.62681,     0.62646,      0.6261,     0.62575,      0.6254,     0.62504,     0.62469,     0.62433,     0.62398,     0.62362,     0.62327,     0.62291,     0.62256,      0.6222,     0.62185,     0.62149,     0.62113,     0.62078,\n",
       "            0.62042,     0.62006,     0.61971,     0.61935,     0.61899,     0.61863,     0.61828,     0.61792,     0.61756,      0.6172,     0.61684,     0.61649,     0.61613,     0.61577,     0.61541,     0.61505,     0.61469,     0.61433,     0.61397,     0.61361,     0.61325,     0.61289,     0.61253,\n",
       "            0.61217,     0.61181,     0.61145,     0.61108,     0.61072,     0.61036,        0.61,     0.60964,     0.60927,     0.60891,     0.60855,     0.60819,     0.60782,     0.60746,      0.6071,     0.60673,     0.60637,       0.606,     0.60564,     0.60528,     0.60491,     0.60431,     0.60312,\n",
       "            0.60193,     0.60074,     0.59954,     0.59834,     0.59715,     0.59594,     0.59474,     0.59354,     0.59233,     0.59112,     0.58991,      0.5887,     0.58748,     0.58626,     0.58504,     0.58382,      0.5826,     0.58137,     0.58014,     0.57891,     0.57768,     0.57645,     0.57521,\n",
       "            0.57397,     0.57273,     0.57149,     0.56833,     0.56506,     0.56178,     0.55848,     0.55517,     0.55184,      0.5485,     0.54514,     0.54177,     0.53838,      0.5353,     0.53257,     0.52984,     0.52709,     0.52434,     0.52157,     0.51879,     0.51601,     0.51321,      0.5104,\n",
       "            0.50758,     0.50475,     0.50191,     0.49899,     0.49592,     0.49283,     0.48974,     0.48663,      0.4835,     0.48037,     0.47722,     0.47406,     0.47088,     0.46769,     0.46449,     0.46134,     0.45883,     0.45632,      0.4538,     0.45127,     0.44873,     0.44619,     0.44363,\n",
       "            0.44107,      0.4385,     0.43592,     0.43333,     0.43074,     0.42813,     0.42552,      0.4229,     0.41951,     0.41429,     0.40905,     0.40377,     0.39845,      0.3931,     0.38772,     0.38229,     0.37654,        0.37,      0.3634,     0.35675,     0.35005,     0.34329,     0.33647,\n",
       "            0.30735,     0.28506,     0.28391,     0.28275,     0.28159,     0.28042,     0.27926,     0.27809,     0.27692,     0.27575,     0.27458,     0.27341,     0.27224,     0.27106,     0.26988,      0.2687,     0.26752,     0.26634,     0.26516,     0.26397,     0.26279,      0.2616,     0.26041,\n",
       "            0.25921,     0.25802,     0.25683,     0.25563,     0.25443,     0.25323,     0.25203,     0.25083,     0.24962,     0.24841,     0.24721,       0.246,     0.24478,     0.24357,     0.24235,     0.24114,     0.23992,      0.2387,     0.23748,     0.23625,     0.23457,     0.23124,      0.2279,\n",
       "            0.22454,     0.22117,     0.21778,     0.21439,     0.21098,     0.20755,     0.20412,     0.20067,     0.19721,     0.19373,     0.19024,     0.18674,     0.18322,     0.17548,     0.16484,     0.15407,     0.14318,     0.13216,      0.1244,     0.12273,     0.12105,     0.11937,     0.11769,\n",
       "              0.116,     0.11431,     0.11262,     0.11092,     0.10922,     0.10752,     0.10581,      0.1041,     0.10239,     0.10068,     0.09896,    0.097239,    0.095515,    0.093788,    0.092058,    0.090325,    0.088589,    0.086849,    0.085106,     0.08336,    0.081611,    0.079859,    0.078103,\n",
       "           0.076344,    0.074583,    0.072817,    0.071049,    0.069277,    0.067502,    0.065724,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.083333,    0.083333,     0.12823,     0.17294,     0.21165,     0.25311,     0.29051,      0.3338,     0.34997,     0.37072,     0.39256,     0.40662,      0.4156,     0.43543,     0.43911,     0.45531,     0.48577,     0.50617,     0.52796,     0.54064,     0.56767,     0.57688,     0.58987,\n",
       "            0.59254,      0.5952,     0.59787,     0.60222,     0.61565,     0.63208,     0.65313,     0.65687,     0.66061,     0.66435,     0.66858,      0.6736,     0.67863,     0.68611,     0.69773,     0.70194,     0.70614,     0.71035,      0.7152,     0.72981,     0.73647,     0.74193,      0.7474,\n",
       "            0.75862,     0.77886,     0.79094,     0.79334,     0.79575,     0.79815,     0.80055,     0.80296,     0.80536,     0.80776,     0.81017,     0.83367,     0.83504,     0.83641,     0.83777,     0.83914,     0.84051,     0.84188,     0.84324,     0.84461,     0.84598,     0.84735,     0.84871,\n",
       "            0.85008,     0.85145,     0.85282,     0.85418,     0.85555,     0.85692,     0.85835,      0.8598,     0.86124,     0.86268,     0.86413,     0.86557,     0.86702,     0.86846,      0.8699,     0.87135,     0.87279,     0.87424,     0.87568,     0.87713,     0.87857,     0.88001,     0.88146,\n",
       "            0.88307,     0.88497,     0.88686,     0.88876,     0.89065,     0.89255,     0.89444,     0.89633,     0.89823,     0.90012,     0.90202,     0.90391,     0.90581,      0.9077,     0.90958,     0.91143,     0.91329,     0.91514,     0.91699,     0.91884,     0.92069,     0.92254,     0.92439,\n",
       "            0.92624,     0.92809,     0.92994,     0.93179,     0.93365,      0.9355,     0.93735,     0.93929,     0.94124,      0.9432,     0.94515,      0.9471,     0.94905,     0.95101,     0.95296,     0.95491,     0.95686,     0.95882,     0.96077,     0.96272,     0.96467,     0.96663,     0.96773,\n",
       "            0.96769,     0.96765,     0.96761,     0.96757,     0.96753,     0.96749,     0.96745,     0.96741,     0.96737,     0.96733,     0.96729,     0.96726,     0.96722,     0.96718,     0.96714,      0.9671,     0.96706,     0.96702,     0.96698,     0.96694,      0.9669,     0.96686,     0.96682,\n",
       "            0.96679,     0.96675,     0.96671,     0.96667,     0.96874,     0.97087,     0.97299,     0.97512,     0.97724,     0.97936,     0.98149,     0.98361,     0.98574,     0.98786,     0.98998,     0.99211,     0.99423,     0.99636,     0.99848,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99948,\n",
       "            0.99827,     0.99705,     0.99584,     0.99462,     0.99341,     0.99219,     0.99098,     0.98977,     0.98855,     0.98734,     0.98612,     0.98491,     0.98369,     0.98248,     0.98127,     0.98005,     0.97884,     0.97762,     0.97641,     0.97519,     0.97398,     0.97277,     0.97155,\n",
       "            0.97034,     0.96912,     0.96791,     0.96669,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96646,     0.96573,       0.965,     0.96427,\n",
       "            0.96353,      0.9628,     0.96207,     0.96134,     0.96061,     0.95988,     0.95915,     0.95842,     0.95769,     0.95695,     0.95622,     0.95549,     0.95476,     0.95403,      0.9533,     0.95257,     0.95184,     0.95111,     0.95037,     0.94964,     0.94891,     0.94818,     0.94745,\n",
       "            0.94672,     0.94599,     0.94526,     0.94452,     0.94379,     0.94306,     0.94233,      0.9416,     0.94087,     0.94014,     0.93941,     0.93868,     0.93794,     0.93721,     0.93648,     0.93575,     0.93502,     0.93429,     0.93356,     0.93147,     0.92879,      0.9261,     0.92342,\n",
       "            0.92073,     0.91805,     0.91536,     0.91268,     0.90999,     0.90731,     0.90462,     0.90194,     0.89989,      0.8995,     0.89911,     0.89872,     0.89833,     0.89794,     0.89755,     0.89716,     0.89677,     0.89638,       0.896,     0.89561,     0.89522,     0.89483,     0.89444,\n",
       "            0.89405,     0.89366,     0.89327,     0.89288,     0.89249,      0.8921,     0.89171,     0.89132,     0.89093,     0.89054,     0.89015,     0.88976,     0.88937,     0.88898,     0.88859,      0.8882,     0.88781,     0.88742,     0.88703,     0.88664,     0.88625,     0.88586,     0.88548,\n",
       "            0.88509,      0.8847,     0.88431,     0.88392,     0.88353,     0.88314,     0.88275,     0.88236,     0.88197,     0.88158,     0.88119,      0.8808,     0.88041,     0.88002,     0.87963,     0.87924,     0.87885,     0.87846,     0.87807,     0.87768,     0.87729,      0.8769,     0.87651,\n",
       "            0.87612,     0.87573,     0.87535,     0.87496,     0.87457,     0.87418,     0.87379,      0.8734,     0.87301,     0.87262,     0.87223,     0.87184,     0.87145,     0.87106,     0.87067,     0.87028,     0.86989,      0.8695,     0.86911,     0.86872,     0.86833,     0.86794,     0.86755,\n",
       "            0.86716,     0.86677,     0.83782,      0.8283,     0.82262,     0.81694,     0.81127,     0.80559,     0.79987,     0.79149,      0.7831,     0.77471,     0.76571,     0.74205,     0.73219,     0.73038,     0.72857,     0.72676,     0.72496,     0.72315,     0.72134,     0.71953,     0.71772,\n",
       "            0.71591,      0.7141,     0.71229,     0.71049,     0.70868,     0.70687,     0.70506,     0.70325,     0.70144,     0.69809,     0.68868,     0.67927,     0.66986,     0.66643,     0.66607,     0.66571,     0.66535,     0.66498,     0.66462,     0.66426,      0.6639,     0.66354,     0.66318,\n",
       "            0.66282,     0.66246,      0.6621,     0.66174,     0.66137,     0.66101,     0.66065,     0.66029,     0.65993,     0.65957,     0.65921,     0.65885,     0.65849,     0.65813,     0.65777,      0.6574,     0.65704,     0.65668,     0.65632,     0.65596,      0.6556,     0.65524,     0.65488,\n",
       "            0.65452,     0.65416,     0.65379,     0.65343,     0.65307,     0.65271,     0.65235,     0.65199,     0.65163,     0.65127,     0.65091,     0.65055,     0.65019,     0.64982,     0.64946,      0.6491,     0.64874,     0.64838,     0.64802,     0.64766,      0.6473,     0.64694,     0.64658,\n",
       "            0.64621,     0.64585,     0.64549,     0.64513,     0.64477,     0.64441,     0.64405,     0.64369,     0.64333,     0.64297,     0.64261,     0.64224,     0.64188,     0.64152,     0.64116,      0.6408,     0.64044,     0.64008,     0.63972,     0.63936,       0.639,     0.63863,     0.63827,\n",
       "            0.63791,     0.63755,     0.63719,     0.63683,     0.63647,     0.63611,     0.63575,     0.63539,     0.63502,     0.63466,      0.6343,     0.63394,     0.63358,     0.63316,     0.63263,     0.63209,     0.63155,     0.63102,     0.63048,     0.62994,      0.6294,     0.62887,     0.62833,\n",
       "            0.62779,     0.62725,     0.62672,     0.62618,     0.62564,      0.6251,     0.62457,     0.62403,     0.62349,     0.62295,     0.62242,     0.62188,     0.62134,     0.62081,     0.62027,     0.61973,     0.61919,     0.61866,     0.61812,     0.61758,     0.61704,     0.61651,     0.61597,\n",
       "            0.61543,     0.61489,     0.61436,     0.61382,     0.61328,     0.61274,     0.61221,     0.61167,     0.61113,      0.6106,     0.61006,     0.60952,     0.60898,     0.60845,     0.60791,     0.60737,     0.60683,      0.6063,     0.60576,     0.60522,     0.60468,     0.60415,     0.60361,\n",
       "            0.60307,     0.60253,       0.602,     0.60146,     0.60092,     0.60039,     0.59989,      0.5995,     0.59911,     0.59872,     0.59833,     0.59794,     0.59755,     0.59716,     0.59677,     0.59638,     0.59599,      0.5956,     0.59521,     0.59482,     0.59443,     0.59404,     0.59365,\n",
       "            0.59326,     0.59287,     0.59248,     0.59209,      0.5917,     0.59131,     0.59092,     0.59053,     0.59014,     0.58975,     0.58936,     0.58897,     0.58858,     0.58819,      0.5878,     0.58741,     0.58702,     0.58663,     0.58624,     0.58585,     0.58546,     0.58507,     0.58468,\n",
       "            0.58429,      0.5839,     0.58351,     0.58312,     0.58273,     0.58234,     0.58195,     0.58156,     0.58117,     0.58078,     0.58039,        0.58,     0.57961,     0.57922,     0.57883,     0.57844,     0.57805,     0.57766,     0.57727,     0.57688,      0.5765,     0.57611,     0.57572,\n",
       "            0.57533,     0.57494,     0.57455,     0.57416,     0.57377,     0.57338,     0.57299,      0.5726,     0.57221,     0.57182,     0.57143,     0.57104,     0.57065,     0.57026,     0.56987,     0.56948,     0.56909,      0.5687,     0.56831,     0.56792,     0.56753,     0.56714,     0.56675,\n",
       "            0.56566,     0.56438,      0.5631,     0.56183,     0.56055,     0.55928,       0.558,     0.55673,     0.55545,     0.55418,      0.5529,     0.55163,     0.55035,     0.54908,      0.5478,     0.54653,     0.54525,     0.54398,      0.5427,     0.54142,     0.54015,     0.53887,      0.5376,\n",
       "            0.53632,     0.53505,     0.53377,     0.53272,     0.53177,     0.53083,     0.52989,     0.52894,       0.528,     0.52706,     0.52612,     0.52517,     0.52423,     0.52329,     0.52235,      0.5214,     0.52046,     0.51952,     0.51857,     0.51763,     0.51669,     0.51575,      0.5148,\n",
       "            0.51386,     0.51292,     0.51197,     0.51103,     0.51009,     0.50915,      0.5082,     0.50726,     0.50632,     0.50538,     0.50443,     0.50349,     0.50255,      0.5016,     0.50066,     0.49982,     0.49921,     0.49861,       0.498,      0.4974,     0.49679,     0.49619,     0.49558,\n",
       "            0.49498,     0.49437,     0.49377,     0.49316,     0.49256,     0.49195,     0.49135,     0.49074,     0.49014,     0.48953,     0.48893,     0.48832,     0.48772,     0.48711,      0.4865,      0.4859,     0.48529,     0.48469,     0.48408,     0.48348,     0.48287,     0.48227,     0.48166,\n",
       "            0.48106,     0.48045,     0.47985,     0.47924,     0.47864,     0.47803,     0.47743,     0.47682,     0.47622,     0.47561,     0.47501,      0.4744,      0.4738,     0.47319,     0.47259,     0.47198,     0.47137,     0.47077,     0.47016,     0.46956,     0.46895,     0.46835,     0.46774,\n",
       "            0.46714,     0.46658,     0.46621,     0.46583,     0.46546,     0.46508,     0.46471,     0.46433,     0.46396,     0.46359,     0.46321,     0.46284,     0.46246,     0.46209,     0.46171,     0.46134,     0.46096,     0.46059,     0.46021,     0.45984,     0.45946,     0.45909,     0.45871,\n",
       "            0.45834,     0.45796,     0.45759,     0.45721,     0.45684,     0.45646,     0.45609,     0.45571,     0.45534,     0.45496,     0.45459,     0.45421,     0.45384,     0.45347,     0.45309,     0.45272,     0.45234,     0.45197,     0.45159,     0.45122,     0.45084,     0.45047,     0.45009,\n",
       "            0.44972,     0.44934,     0.44897,     0.44859,     0.44822,     0.44784,     0.44747,     0.44709,     0.44672,     0.44634,     0.44597,     0.44559,     0.44522,     0.44484,     0.44447,     0.44409,     0.44372,     0.44335,     0.44297,      0.4426,     0.44222,     0.44185,     0.44147,\n",
       "             0.4411,     0.44072,     0.44035,     0.43997,      0.4396,     0.43922,     0.43885,     0.43847,      0.4381,     0.43772,     0.43735,     0.43697,      0.4366,     0.43622,     0.43585,     0.43547,      0.4351,     0.43472,     0.43435,     0.43397,      0.4336,     0.43298,     0.43176,\n",
       "            0.43054,     0.42932,      0.4281,     0.42688,     0.42566,     0.42444,     0.42323,     0.42201,     0.42079,     0.41957,     0.41835,     0.41713,     0.41591,     0.41469,     0.41347,     0.41225,     0.41103,     0.40981,     0.40859,     0.40737,     0.40615,     0.40493,     0.40371,\n",
       "             0.4025,     0.40128,     0.40006,     0.39697,     0.39379,     0.39061,     0.38742,     0.38424,     0.38106,     0.37788,      0.3747,     0.37152,     0.36834,     0.36547,     0.36293,     0.36039,     0.35786,     0.35532,     0.35279,     0.35025,     0.34771,     0.34518,     0.34264,\n",
       "            0.34011,     0.33757,     0.33503,     0.33244,     0.32971,     0.32699,     0.32427,     0.32155,     0.31883,     0.31611,     0.31339,     0.31066,     0.30794,     0.30522,      0.3025,     0.29983,     0.29772,      0.2956,     0.29349,     0.29138,     0.28927,     0.28716,     0.28504,\n",
       "            0.28293,     0.28082,     0.27871,      0.2766,     0.27448,     0.27237,     0.27026,     0.26815,     0.26543,     0.26127,     0.25711,     0.25295,     0.24879,     0.24463,     0.24048,     0.23632,     0.23194,     0.22699,     0.22205,      0.2171,     0.21216,     0.20721,     0.20227,\n",
       "            0.18158,     0.16622,     0.16544,     0.16465,     0.16386,     0.16308,     0.16229,      0.1615,     0.16071,     0.15993,     0.15914,     0.15835,     0.15757,     0.15678,     0.15599,      0.1552,     0.15442,     0.15363,     0.15284,     0.15206,     0.15127,     0.15048,     0.14969,\n",
       "            0.14891,     0.14812,     0.14733,     0.14655,     0.14576,     0.14497,     0.14418,      0.1434,     0.14261,     0.14182,     0.14103,     0.14025,     0.13946,     0.13867,     0.13789,      0.1371,     0.13631,     0.13552,     0.13474,     0.13395,     0.13287,     0.13074,      0.1286,\n",
       "            0.12647,     0.12433,      0.1222,     0.12006,     0.11793,     0.11579,     0.11366,     0.11152,     0.10939,     0.10726,     0.10512,     0.10299,     0.10085,    0.096179,    0.089823,    0.083467,    0.077111,    0.070755,    0.066327,    0.065376,    0.064424,    0.063473,    0.062522,\n",
       "            0.06157,    0.060619,    0.059667,    0.058716,    0.057764,    0.056813,    0.055861,     0.05491,    0.053959,    0.053007,    0.052056,    0.051104,    0.050153,    0.049201,     0.04825,    0.047299,    0.046347,    0.045396,    0.044444,    0.043493,    0.042541,     0.04159,    0.040639,\n",
       "           0.039687,    0.038736,    0.037784,    0.036833,    0.035881,     0.03493,    0.033979,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.7615308350417609)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,\n",
       "            0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,\n",
       "            0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,\n",
       "            0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357,      0.7357])\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'TV', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush', 80: 'Oussama'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.9814879304370557), 'metrics/recall(B)': np.float64(0.9666666666666667), 'metrics/mAP50(B)': np.float64(0.9940322580645161), 'metrics/mAP50-95(B)': np.float64(0.735697343594788), 'fitness': np.float64(0.7615308350417609)}\n",
       "save_dir: WindowsPath('runs/detect/train')\n",
       "speed: {'preprocess': 2.681509653727214, 'inference': 155.86547056833902, 'loss': 0.0, 'postprocess': 1.3411998748779297}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dit is het totale aantal layers\n",
    "num_layers = len(list(model.model.model))\n",
    "print(f\"Totale aantal lagen: {num_layers}\")\n",
    "\n",
    "\n",
    "# Nu gaan we het model trainen\n",
    "model.train(\n",
    "    data = \"custom_dataset.yaml\",\n",
    "    epochs = 50,\n",
    "    batch = 8,\n",
    "    patience = 10,\n",
    "    freeze = num_layers-1,\n",
    "    val = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b06781-d62c-47d1-b3c6-d3837b572172",
   "metadata": {},
   "source": [
    "# Model Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d452244-b9d2-47c6-84dc-f9fc9b5d0b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\OussamaAkhiyat\\Documents\\Python Codes\\Omni\\cat.JPG: 640x640 2 Oussamas, 331.8ms\n",
      "Speed: 9.9ms preprocess, 331.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "best_weights_path = os.getcwd() + '/runs/detect/train/weights/best.pt'\n",
    "test_image_path = os.getcwd() + '/cat.JPG'\n",
    "\n",
    "trained_model = YOLO(\"runs/detect/train/weights/best.pt\") \n",
    "results = model.predict(test_image_path, save=True)\n",
    "\n",
    "result_image = results[0].plot()\n",
    "plt.imshow(result_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
